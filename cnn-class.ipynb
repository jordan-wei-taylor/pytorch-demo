{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from   time import time\n",
    "from   torchvision import datasets, transforms\n",
    "from   torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform   = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "trainset    = datasets.MNIST('train', download = True, train = True , transform = transform)\n",
    "valset      = datasets.MNIST('val  ', download = True, train = False, transform = transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "valloader   = torch.utils.data.DataLoader(valset  , batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.fc  = nn.Linear(32 * 7 * 7, 10)\n",
    "        self.out = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)   \n",
    "        output = self.out(x)\n",
    "        return output# , x    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "\n",
    "criterion      = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images         = images.view(64, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 - Training loss: 0.175144955282038\n",
      "Epoch   2 - Training loss: 0.08667568550201883\n",
      "Epoch   3 - Training loss: 0.07671116758857781\n",
      "Epoch   4 - Training loss: 0.0788451449182664\n",
      "Epoch   5 - Training loss: 0.0695262154278684\n",
      "\n",
      "Training Time = 1m 4s\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 1e-2)\n",
    "time0     = time()\n",
    "epochs    = 5\n",
    "\n",
    "for e in range(1, epochs + 1):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(-1, 1, 28, 28)\n",
    "    \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        #This is where the model learns by backpropagating\n",
    "        loss.backward()\n",
    "        \n",
    "        #And optimizes its weights here\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {e:3d} - Training loss: {running_loss / len(trainloader)}\")\n",
    "\n",
    "m, s = map(int, divmod(time() - time0, 60))\n",
    "if s == 60:\n",
    "    m += 1\n",
    "    s  = 0\n",
    "print(f\"\\nTraining Time = {m:d}m {s:d}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9808"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat  = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for images, label in valloader:\n",
    "        images = images.view(-1, 1, 28, 28)\n",
    "        logp   = model(images)\n",
    "        y_hat.append(logp.numpy().argmax(axis = -1))\n",
    "        y_true.append(label.numpy())\n",
    "\n",
    "y_hat  = np.concatenate(y_hat)\n",
    "y_true = np.concatenate(y_true)\n",
    "\n",
    "(y_hat == y_true).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.98, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.01],\n",
       "       [0.  , 0.  , 0.  , 0.01, 0.  , 0.98, 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.01, 0.  , 0.  , 0.  , 0.01, 0.  , 0.98, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.01, 0.01, 0.  , 0.  , 0.  , 0.  , 0.98, 0.  , 0.  ],\n",
       "       [0.01, 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.98, 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.  , 0.01, 0.  , 0.95]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true, y_hat, normalize = 'true')\n",
    "\n",
    "cm.round(2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4847ad505881de8140e092bfe0cfa380e6b65d29a16b93ff5f646bbaa0593f53"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
